{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling of the thickness of the sensor\n",
    "\n",
    "In this notebook we will re-use the experiment done at ID28 and previously calibrated and model in 3D the detector.\n",
    "\n",
    "This detector is a Pilatus 1M with a 450µm thick silicon sensor. Let's first have a look at the absorption coefficients of this sensor material: https://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/z14.html\n",
    "\n",
    "First we retieve the results of the previous step, then calculate the absorption efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# use `widget` instead of `inline` for better user-exeperience. `inline` allows to store plots into notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.perf_counter()\n",
    "from matplotlib.pyplot import subplots\n",
    "import numpy\n",
    "import fabio, pyFAI, pyFAI.units, pyFAI.detectors\n",
    "import json\n",
    "with open(\"id28.json\") as f:\n",
    "    calib = json.load(f)\n",
    "\n",
    "thickness = 450e-6\n",
    "wavelength = calib[\"wavelength\"]\n",
    "dist = calib[\"param\"][calib['param_names'].index(\"dist\")]\n",
    "poni1 = calib[\"param\"][calib['param_names'].index(\"poni1\")]\n",
    "poni2 = calib[\"param\"][calib['param_names'].index(\"poni2\")]\n",
    "energy = pyFAI.units.hc/(wavelength*1e10)\n",
    "print(\"wavelength: %.3em,\\t dist: %.3em,\\t poni1: %.3em,\\t poni2: %.3em,\\t energy: %.3fkeV\" % \n",
    "      (wavelength, dist, poni1, poni2, energy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absorption coefficient at 17.8 keV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density from https://en.wikipedia.org/wiki/Silicon\n",
    "rho = 2.3290 # g/cm^3\n",
    "\n",
    "#Absorption from https://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/z14.html\n",
    "# Nota: energies are in MeV !\n",
    "Si_abs = \"\"\"\n",
    "   2.00000E-03  2.777E+03  2.669E+03 \n",
    "   3.00000E-03  9.784E+02  9.516E+02 \n",
    "   4.00000E-03  4.529E+02  4.427E+02 \n",
    "   5.00000E-03  2.450E+02  2.400E+02 \n",
    "   6.00000E-03  1.470E+02  1.439E+02 \n",
    "   8.00000E-03  6.468E+01  6.313E+01 \n",
    "   1.00000E-02  3.389E+01  3.289E+01 \n",
    "   1.50000E-02  1.034E+01  9.794E+00 \n",
    "   2.00000E-02  4.464E+00  4.076E+00 \n",
    "   3.00000E-02  1.436E+00  1.164E+00 \n",
    "   4.00000E-02  7.012E-01  4.782E-01 \n",
    "   5.00000E-02  4.385E-01  2.430E-01 \n",
    "   6.00000E-02  3.207E-01  1.434E-01 \n",
    "   8.00000E-02  2.228E-01  6.896E-02 \n",
    "   1.00000E-01  1.835E-01  4.513E-02 \n",
    "   1.50000E-01  1.448E-01  3.086E-02 \n",
    "   2.00000E-01  1.275E-01  2.905E-02 \n",
    "   3.00000E-01  1.082E-01  2.932E-02 \n",
    "   4.00000E-01  9.614E-02  2.968E-02 \n",
    "   5.00000E-01  8.748E-02  2.971E-02 \n",
    "   6.00000E-01  8.077E-02  2.951E-02 \n",
    "   8.00000E-01  7.082E-02  2.875E-02 \n",
    "   1.00000E+00  6.361E-02  2.778E-02 \n",
    "   1.25000E+00  5.688E-02  2.652E-02 \n",
    "   1.50000E+00  5.183E-02  2.535E-02 \n",
    "   2.00000E+00  4.480E-02  2.345E-02 \n",
    "   3.00000E+00  3.678E-02  2.101E-02 \n",
    "   4.00000E+00  3.240E-02  1.963E-02 \n",
    "   5.00000E+00  2.967E-02  1.878E-02 \n",
    "   6.00000E+00  2.788E-02  1.827E-02 \n",
    "   8.00000E+00  2.574E-02  1.773E-02 \n",
    "   1.00000E+01  2.462E-02  1.753E-02 \n",
    "   1.50000E+01  2.352E-02  1.746E-02 \n",
    "   2.00000E+01  2.338E-02  1.757E-02 \"\"\"\n",
    "data = numpy.array([[float(i) for i in line.split()] for line in Si_abs.split(\"\\n\") if line])\n",
    "energy_tab, mu_over_rho, mu_en_over_rho = data.T\n",
    "abs_18 = numpy.interp(energy, energy_tab*1e3, mu_en_over_rho) \n",
    "mu = abs_18*rho*1e+2\n",
    "eff = 1.0-numpy.exp(-mu*thickness)\n",
    "\n",
    "print(\"µ = %f m^-1 hence absorption efficiency for 450µm: %.1f %%\"%(mu, eff*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = numpy.linspace(0, 1000, 100)\n",
    "res = numpy.exp(-mu*depth*1e-6)\n",
    "fig, ax = subplots()\n",
    "ax.plot(depth, res, \"-\")\n",
    "ax.set_xlabel(\"Depth (µm)\")\n",
    "ax.set_ylabel(\"Residual signal\")\n",
    "ax.set_title(\"Silicon @ 17.8 keV\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is consistent with:\n",
    "http://henke.lbl.gov/optical_constants/filter2.html\n",
    "\n",
    "Now we can model the detector\n",
    "\n",
    "## Modeling of the detector:\n",
    "\n",
    "The detector is represented as a 2D array of voxels. Let vox, voy, and voz denote the dimensions of the detector along the three axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector= pyFAI.detector_factory(calib[\"detector\"])\n",
    "print(detector)\n",
    "\n",
    "vox = detector.pixel2 # this is not a typo\n",
    "voy = detector.pixel1 # x <--> axis 2\n",
    "voz = thickness\n",
    "\n",
    "print(vox, voy, voz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intensity grabbed in this voxel is the triple integral of the absorbed signal coming from this pixel or from the neighboring ones.\n",
    "\n",
    "There are 3 ways to perform this intergral:\n",
    "* Volumetric analytic integral. Looks feasible with a change of variable in the depth\n",
    "* Slice per slice, the remaining intensity depand on the incidence angle + pixel splitting between neighbooring pixels\n",
    "* raytracing: the decay can be solved analytically for each ray, one has to throw many ray to average out the signal.\n",
    "\n",
    "For sake of simplicity, this integral will be calculated numerically using this raytracing algorithm.\n",
    "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.3443&rep=rep1&type=pdf\n",
    "\n",
    "Knowing the input position for a X-ray on the detector and its propagation vector, this algorithm allows us to calculate  the length of the path in all voxel it crosses in a fairly efficient way.\n",
    "\n",
    "To speed up the calculation, we will use a few tricks:\n",
    "* One ray never crosses more than 16 pixels, which is reasonable considering the incidance angle \n",
    "* we use numba to speed-up the calculation of loops in python\n",
    "* We will allocate the needed memory by chuncks of 1 million elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit \n",
    "\n",
    "BLOCK_SIZE = 1<<20 # 1 million\n",
    "BUFFER_SIZE = 16 \n",
    "BIG = numpy.finfo(numpy.float32).max\n",
    "\n",
    "mask = numpy.load(\"mask.npy\").astype(numpy.int8)\n",
    "from scipy.sparse import csr_matrix, csc_matrix, linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calc_one_ray(entx, enty, \n",
    "                 kx, ky, kz,\n",
    "                 vox, voy, voz):\n",
    "    \"\"\"For a ray entering at position (entx, enty) with a propagation vector (kx, ky, kz), \n",
    "    calculate the path length within each voxel where energy is deposited from a bunch of photons entering the detector\n",
    "      at a given position, and determine how much energy is deposited in each voxel.\n",
    "\n",
    "    \n",
    "    Direct implementation of http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.3443&rep=rep1&type=pdf\n",
    "    \n",
    "    :param entx, enty: coordinate of the entry point in meter (2 components, x,y)\n",
    "    :param kx, ky, kz: vector with the direction of the photon (3 components, x,y,z)\n",
    "    :param vox, voy, voz: size of the voxel in meter (3 components, x,y,z)\n",
    "    :return: coordinates voxels in x, y and length crossed when leaving the associated voxel\n",
    "    \"\"\"\n",
    "    array_x = numpy.empty(BUFFER_SIZE, dtype=numpy.int32)\n",
    "    array_x[:] = -1\n",
    "    array_y = numpy.empty(BUFFER_SIZE, dtype=numpy.int32)\n",
    "    array_y[:] = -1\n",
    "    array_len = numpy.empty(BUFFER_SIZE, dtype=numpy.float32)\n",
    "    \n",
    "    #normalize the input propagation vector\n",
    "    n = numpy.sqrt(kx*kx + ky*ky + kz*kz)\n",
    "    kx /= n\n",
    "    ky /= n\n",
    "    kz /= n\n",
    "    \n",
    "    #assert kz>0\n",
    "    step_X = -1 if kx<0.0 else 1\n",
    "    step_Y = -1 if ky<0.0 else 1\n",
    "    \n",
    "    #assert vox>0\n",
    "    #assert voy>0\n",
    "    #assert voz>0\n",
    "        \n",
    "    X = int(entx//vox)\n",
    "    Y = int(enty//voy)\n",
    "    \n",
    "    if kx>0.0:\n",
    "        t_max_x = ((entx//vox+1)*(vox)-entx)/ kx\n",
    "    elif kx<0.0:\n",
    "        t_max_x = ((entx//vox)*(vox)-entx)/ kx\n",
    "    else:\n",
    "        t_max_x = BIG\n",
    "\n",
    "    if ky>0.0:\n",
    "        t_max_y = ((enty//voy+1)*(voy)-enty)/ ky\n",
    "    elif ky<0.0:\n",
    "        t_max_y = ((enty//voy)*(voy)-enty)/ ky\n",
    "    else:\n",
    "        t_max_y = BIG\n",
    "    \n",
    "    #Only one case for z as the ray is travelling in one direction only\n",
    "    t_max_z = voz / kz\n",
    "       \n",
    "    t_delta_x = abs(vox/kx) if kx!=0 else BIG\n",
    "    t_delta_y = abs(voy/ky) if ky!=0 else BIG\n",
    "    t_delta_z = voz/kz\n",
    "    \n",
    "    finished = False\n",
    "    last_id = 0\n",
    "    array_x[last_id] = X\n",
    "    array_y[last_id] = Y\n",
    "    \n",
    "    while not finished:\n",
    "        if t_max_x < t_max_y:\n",
    "            if t_max_x < t_max_z:\n",
    "                array_len[last_id] = t_max_x\n",
    "                last_id+=1\n",
    "                X += step_X\n",
    "                array_x[last_id] = X\n",
    "                array_y[last_id] = Y\n",
    "                t_max_x += t_delta_x\n",
    "            else:\n",
    "                array_len[last_id] = t_max_z\n",
    "                finished = True\n",
    "        else:\n",
    "            if t_max_y < t_max_z:\n",
    "                array_len[last_id] = t_max_y\n",
    "                last_id+=1\n",
    "                Y += step_Y\n",
    "                array_x[last_id] = X\n",
    "                array_y[last_id] = Y                \n",
    "                t_max_y += t_delta_y\n",
    "            else:\n",
    "                array_len[last_id] = t_max_z\n",
    "                finished = True\n",
    "        if last_id>=array_len.size-1:\n",
    "            print(\"resize arrays\")\n",
    "            old_size = len(array_len)\n",
    "            new_size = (old_size//BUFFER_SIZE+1)*BUFFER_SIZE\n",
    "            new_array_x = numpy.empty(new_size, dtype=numpy.int32)\n",
    "            new_array_x[:] = -1\n",
    "            new_array_y = numpy.empty(new_size, dtype=numpy.int32)\n",
    "            new_array_y[:] = -1\n",
    "            new_array_len = numpy.empty(new_size, dtype=numpy.float32)\n",
    "            new_array_x[:old_size] = array_x\n",
    "            new_array_y[:old_size] = array_y\n",
    "            new_array_len[:old_size] = array_len\n",
    "            array_x = new_array_x\n",
    "            array_y = new_array_y\n",
    "            array_len = new_array_len\n",
    "    return array_x[:last_id], array_y[:last_id], array_len[:last_id]\n",
    "\n",
    "print(calc_one_ray(0.0,0.0, 1,1,1, 172e-6, 172e-6, 450e-6))\n",
    "import random\n",
    "%timeit calc_one_ray(10+random.random(),11+random.random(),\\\n",
    "                     random.random()-0.5,random.random()-0.5,0.5+random.random(), \\\n",
    "                     vox, voy, voz)\n",
    "%timeit calc_one_ray.py_func(10+random.random(),11+random.random(),\\\n",
    "                     random.random()-0.5,random.random()-0.5,0.5+random.random(), \\\n",
    "                     vox, voy, voz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we are able to perform raytracing for any ray comming in the detector, we can calculate the contribution to the neighboring pixels, using the absorption law (the length travelled is already known). \n",
    "To average-out the signal, we will sample a few dozens of rays per pixel to get an approximatation of the volumic integrale. \n",
    "\n",
    "Now we need to store the results so that this transformation can be represented as a sparse matrix multiplication:\n",
    "\n",
    "b = M.a\n",
    "\n",
    "Where b is the recorded image (blurred) and a is the \"perfect\" signal. \n",
    "M being the sparse matrix where every pixel of a gives a limited number of contribution to b.\n",
    "\n",
    "Each pixel in *b* is represented by one line in *M* and we store the indices of *a* of interest with the coefficients of the matrix.\n",
    "So if a pixel i,j contributes to (i,j), (i+1,j), (i+1,j+1), there are only 3 elements in the line. \n",
    "This is advantagous for storage.\n",
    "\n",
    "We will use the CSR sparse matrix representation:\n",
    "https://en.wikipedia.org/wiki/Sparse_matrix#Compressed_sparse_row_.28CSR.2C_CRS_or_Yale_format.29\n",
    "where there are 3 arrays:\n",
    "* data: containing the actual non zero values\n",
    "* indices: for a given line, it contains the column number of the assocated data (at the same indice)\n",
    "* idptr: this array contains the index of the start of every line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.experimental import jitclass\n",
    "from numba import int8, int32, int64, float32, float64\n",
    "spec = [(\"vox\",float64),(\"voy\",float64),(\"voz\",float64),(\"mu\",float64),\n",
    "        (\"dist\",float64),(\"poni1\",float64),(\"poni2\",float64),\n",
    "        (\"width\", int64),(\"height\", int64),(\"mask\", int8[:,:]),\n",
    "        (\"sampled\", int64), (\"data\", float32[:]),(\"indices\", int32[:]),(\"idptr\", int32[:]),\n",
    "       ]\n",
    "@jitclass(spec)\n",
    "class ThickDetector(object):\n",
    "    \"Calculate the point spread function as function of the geometry of the experiment\"\n",
    "    \n",
    "    def __init__(self, vox, voy, thickness, mask, mu, \n",
    "                 dist, poni1, poni2):\n",
    "        \"\"\"Constructor of the class:\n",
    "        \n",
    "        :param vox, voy: detector pixel size in the plane\n",
    "        :param thickness: thickness of the sensor in meters\n",
    "        :param mask: \n",
    "        :param mu: absorption coefficient of the sensor material\n",
    "        :param dist: sample detector distance as defined in the geometry-file\n",
    "        :param poni1, poni2: coordinates of the PONI as defined in the geometry \n",
    "        \"\"\"\n",
    "        self.vox = vox\n",
    "        self.voy = voy\n",
    "        self.voz = thickness\n",
    "        self.mu = mu\n",
    "        self.dist=dist\n",
    "        self.poni1 = poni1\n",
    "        self.poni2 = poni2\n",
    "        self.width = mask.shape[-1]\n",
    "        self.height = mask.shape[0]\n",
    "        self.mask = mask\n",
    "        self.sampled = 0\n",
    "        self.data = numpy.zeros(BLOCK_SIZE, dtype=numpy.float32)\n",
    "        self.indices = numpy.zeros(BLOCK_SIZE,dtype=numpy.int32)\n",
    "        self.idptr = numpy.zeros(self.width*self.height+1, dtype=numpy.int32)\n",
    "        \n",
    "    def calc_one_ray(self, entx, enty):\n",
    "        \"\"\"For a ray, entering at position (entx, enty), with a propagation vector (kx, ky,kz),\n",
    "        calculate the length spent in every voxel where energy is deposited from a bunch of photons comming in the detector \n",
    "        at a given position and and how much energy they deposit in each voxel. \n",
    "\n",
    "        Direct implementation of http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.42.3443&rep=rep1&type=pdf\n",
    "\n",
    "        :param entx, enty: coordinate of the entry point in meter (2 components, x,y)\n",
    "        :return: coordinates voxels in x, y and length crossed when leaving the associated voxel\n",
    "        \"\"\"\n",
    "        array_x = numpy.empty(BUFFER_SIZE, dtype=numpy.int32)\n",
    "        array_x[:] = -1\n",
    "        array_y = numpy.empty(BUFFER_SIZE, dtype=numpy.int32)\n",
    "        array_y[:] = -1\n",
    "        array_len = numpy.empty(BUFFER_SIZE, dtype=numpy.float32)\n",
    "\n",
    "        #normalize the input propagation vector\n",
    "        kx = entx - self.poni2\n",
    "        ky = enty - self.poni1\n",
    "        kz = self.dist\n",
    "        n = numpy.sqrt(kx*kx + ky*ky + kz*kz)\n",
    "        kx /= n\n",
    "        ky /= n\n",
    "        kz /= n\n",
    "\n",
    "        step_X = -1 if kx<0.0 else 1\n",
    "        step_Y = -1 if ky<0.0 else 1\n",
    "\n",
    "        X = int(entx/self.vox)\n",
    "        Y = int(enty/self.voy)\n",
    "\n",
    "        if kx>0.0:\n",
    "            t_max_x = ((entx//self.vox+1)*(self.vox)-entx)/ kx\n",
    "        elif kx<0.0:\n",
    "            t_max_x = ((entx//self.vox)*(self.vox)-entx)/ kx\n",
    "        else:\n",
    "            t_max_x = BIG\n",
    "\n",
    "        if ky>0.0:\n",
    "            t_max_y = ((enty//self.voy+1)*(self.voy)-enty)/ ky\n",
    "        elif ky<0.0:\n",
    "            t_max_y = ((enty//self.voy)*(self.voy)-enty)/ ky\n",
    "        else:\n",
    "            t_max_y = BIG\n",
    "\n",
    "        #Only one case for z as the ray is travelling in one direction only\n",
    "        t_max_z = self.voz / kz\n",
    "\n",
    "        t_delta_x = abs(self.vox/kx) if kx!=0 else BIG\n",
    "        t_delta_y = abs(self.voy/ky) if ky!=0 else BIG\n",
    "        t_delta_z = self.voz/kz\n",
    "\n",
    "        finished = False\n",
    "        last_id = 0\n",
    "        array_x[last_id] = X\n",
    "        array_y[last_id] = Y\n",
    "\n",
    "        while not finished:\n",
    "            if t_max_x < t_max_y:\n",
    "                if t_max_x < t_max_z:\n",
    "                    array_len[last_id] = t_max_x\n",
    "                    last_id+=1\n",
    "                    X += step_X\n",
    "                    array_x[last_id] = X\n",
    "                    array_y[last_id] = Y\n",
    "                    t_max_x += t_delta_x\n",
    "                else:\n",
    "                    array_len[last_id] = t_max_z\n",
    "                    last_id+=1\n",
    "                    finished = True\n",
    "            else:\n",
    "                if t_max_y < t_max_z:\n",
    "                    array_len[last_id] = t_max_y\n",
    "                    last_id+=1\n",
    "                    Y += step_Y\n",
    "                    array_x[last_id] = X\n",
    "                    array_y[last_id] = Y                \n",
    "                    t_max_y += t_delta_y\n",
    "                else:\n",
    "                    array_len[last_id] = t_max_z\n",
    "                    last_id+=1\n",
    "                    finished = True\n",
    "            if last_id>=array_len.size-1:\n",
    "                print(\"resize arrays\")\n",
    "                old_size = len(array_len)\n",
    "                new_size = (old_size//BUFFER_SIZE+1)*BUFFER_SIZE\n",
    "                new_array_x = numpy.empty(new_size, dtype=numpy.int32)\n",
    "                new_array_x[:] = -1\n",
    "                new_array_y = numpy.empty(new_size, dtype=numpy.int32)\n",
    "                new_array_y[:] = -1\n",
    "                new_array_len = numpy.empty(new_size, dtype=numpy.float32)\n",
    "                new_array_x[:old_size] = array_x\n",
    "                new_array_y[:old_size] = array_y\n",
    "                new_array_len[:old_size] = array_len\n",
    "                array_x = new_array_x\n",
    "                array_y = new_array_y\n",
    "                array_len = new_array_len\n",
    "        return array_x[:last_id], array_y[:last_id], array_len[:last_id]\n",
    "\n",
    "    def one_pixel(self, row, col, sample):\n",
    "        \"\"\"calculate the contribution of one pixel to the sparse matrix and populate it.\n",
    "\n",
    "        :param row: row index of the pixel of interest\n",
    "        :param col: column index of the pixel of interest\n",
    "        :param sample: Oversampling rate, 10 will thow 10x10 ray per pixel\n",
    "\n",
    "        :return: the extra number of pixel allocated\n",
    "        \"\"\"\n",
    "        if self.mask[row, col]:\n",
    "            return (numpy.empty(0, dtype=numpy.int32),\n",
    "                    numpy.empty(0, dtype=numpy.float32))\n",
    "\n",
    "        counter = 0\n",
    "        tmp_size = 0\n",
    "        last_buffer_size = BUFFER_SIZE\n",
    "        tmp_idx = numpy.empty(last_buffer_size, dtype=numpy.int32)\n",
    "        tmp_idx[:] = -1\n",
    "        tmp_coef = numpy.zeros(last_buffer_size, dtype=numpy.float32)\n",
    "\n",
    "        pos = row * self.width + col\n",
    "        start = self.idptr[pos]\n",
    "        for i in range(sample):\n",
    "            posx = (col+1.0*i/sample)*vox\n",
    "            for j in range(sample):\n",
    "                posy = (row+1.0*j/sample)*voy\n",
    "                array_x, array_y, array_len = self.calc_one_ray(posx, posy)\n",
    "\n",
    "                rem = 1.0\n",
    "                for i in range(array_x.size):\n",
    "                    x = array_x[i]\n",
    "                    y = array_y[i]\n",
    "                    l = array_len[i]\n",
    "                    if (x<0) or (y<0) or (y>=self.height) or (x>=self.width):\n",
    "                        break\n",
    "                    elif (self.mask[y, x]):\n",
    "                        continue\n",
    "                    idx = x + y*self.width\n",
    "                    dos = numpy.exp(-self.mu*l)\n",
    "                    value = rem - dos\n",
    "                    rem = dos\n",
    "                    for j in range(last_buffer_size):\n",
    "                        if tmp_size >= last_buffer_size:\n",
    "                            #Increase buffer size\n",
    "                            new_buffer_size = last_buffer_size + BUFFER_SIZE\n",
    "                            new_idx = numpy.empty(new_buffer_size, dtype=numpy.int32)\n",
    "                            new_coef = numpy.zeros(new_buffer_size, dtype=numpy.float32)\n",
    "                            new_idx[:last_buffer_size] = tmp_idx\n",
    "                            new_idx[last_buffer_size:] = -1\n",
    "                            new_coef[:last_buffer_size] = tmp_coef\n",
    "                            last_buffer_size = new_buffer_size\n",
    "                            tmp_idx = new_idx\n",
    "                            tmp_coef = new_coef\n",
    "\n",
    "                        if tmp_idx[j] == idx:\n",
    "                            tmp_coef[j] += value\n",
    "                            break\n",
    "                        elif tmp_idx[j] < 0:\n",
    "                            tmp_idx[j] = idx\n",
    "                            tmp_coef[j] = value\n",
    "                            tmp_size +=1\n",
    "                            break     \n",
    "        return tmp_idx[:tmp_size], tmp_coef[:tmp_size]\n",
    "\n",
    "    def calc_csr(self, sample):\n",
    "        \"\"\"Calculate the CSR matrix for the whole image\n",
    "        :param sample: Oversampling factor\n",
    "        :return: CSR matrix\n",
    "        \"\"\"\n",
    "        size = self.width * self.height\n",
    "        allocated_size = BLOCK_SIZE\n",
    "        idptr = numpy.zeros(size+1, dtype=numpy.int32) \n",
    "        indices = numpy.zeros(allocated_size, dtype=numpy.int32)\n",
    "        data = numpy.zeros(allocated_size, dtype=numpy.float32)\n",
    "        self.sampled = sample*sample\n",
    "        pos = 0\n",
    "        start = 0\n",
    "        for row in range(self.height):\n",
    "            for col in range(self.width):    \n",
    "                line_idx, line_coef = self.one_pixel(row, col, sample)\n",
    "                line_size = line_idx.size\n",
    "                if line_size == 0:\n",
    "                    new_size = 0\n",
    "                    pos+=1\n",
    "                    idptr[pos] = start\n",
    "                    continue\n",
    "\n",
    "                stop = start + line_size\n",
    "                \n",
    "                if stop >= allocated_size:\n",
    "                    new_buffer_size = allocated_size +  BLOCK_SIZE\n",
    "                    new_idx = numpy.zeros(new_buffer_size, dtype=numpy.int32)\n",
    "                    new_coef = numpy.zeros(new_buffer_size, dtype=numpy.float32)\n",
    "                    new_idx[:allocated_size] = indices\n",
    "                    new_coef[:allocated_size] = data\n",
    "                    allocated_size = new_buffer_size\n",
    "                    indices = new_idx\n",
    "                    data = new_coef\n",
    "\n",
    "                indices[start:stop] = line_idx\n",
    "                data[start:stop] = line_coef\n",
    "                pos+=1\n",
    "                idptr[pos] = stop\n",
    "                start = stop\n",
    "    \n",
    "        last = idptr[-1]\n",
    "        self.data = data\n",
    "        self.indices = indices\n",
    "        self.idptr = idptr\n",
    "        return (self.data[:last]/self.sampled, indices[:last], idptr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thick = ThickDetector(vox,voy, thickness=thickness, mu=mu, dist=dist, poni1=poni1, poni2=poni2, mask=mask)\n",
    "%time thick.calc_csr(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thick = ThickDetector(vox,voy, thickness=thickness, mu=mu, dist=dist, poni1=poni1, poni2=poni2, mask=mask)\n",
    "%time pre_csr = thick.calc_csr(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of the CSR matrix obtained:\n",
    "\n",
    "For this we will build a simple 2D image with one pixel in a regular grid and calculate the effect of the transformation calculated previously on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_image = numpy.ones(mask.shape, dtype=\"float32\")\n",
    "dummy_image[::5,::5] = 10\n",
    "#dummy_image[mask] = -1\n",
    "csr = csr_matrix(pre_csr)\n",
    "dummy_blurred = csr.T.dot(dummy_image.ravel()).reshape(mask.shape)\n",
    "fix, ax = subplots(2,2, figsize=(8,8))\n",
    "ax[0,0].imshow(dummy_image)\n",
    "ax[0,1].imshow(dummy_blurred)\n",
    "ax[1,1].imshow(csr.dot(dummy_blurred.ravel()).reshape(mask.shape))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax[0,0].set_xlim(964,981)\n",
    "ax[0,0].set_ylim(0,16)\n",
    "ax[0,1].set_xlim(964,981)\n",
    "ax[0,1].set_ylim(0,16)\n",
    "ax[1,1].set_xlim(964,981)\n",
    "ax[1,1].set_ylim(0,16)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares refinement of the pseudo-inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blured = dummy_blurred.ravel()\n",
    "\n",
    "# Invert this matrix: see https://arxiv.org/abs/1006.0758\n",
    "\n",
    "%time res = linalg.lsmr(csr.T, blured)\n",
    "\n",
    "restored = res[0].reshape(mask.shape)\n",
    "ax[1,0].imshow(restored)\n",
    "ax[1,0].set_xlim(964,981)\n",
    "ax[1,0].set_ylim(0,16)\n",
    "\n",
    "print(res[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo inverse with positivitiy constrain and poissonian noise (MLEM)\n",
    "\n",
    "The MLEM algorithm was initially developed within the framework of reconstruction of\n",
    "images in emission tomography [Shepp and Vardi, 1982], [Vardi et al., 1985], [Lange and\n",
    "Carson, 1984]. Nowadays, this algorithm is employed in numerous tomographic reconstruction\n",
    "problems and often associated to regularization techniques. It is based on the iterative\n",
    "maximization of the log-likelihood function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = subplots(2,2, figsize=(8,8))\n",
    "ax[0,0].imshow(dummy_image)\n",
    "ax[0,1].imshow(dummy_blurred)\n",
    "ax[1,1].imshow(csr.dot(dummy_blurred.ravel()).reshape(mask.shape))\n",
    "ax[0,0].set_xlim(964,981)\n",
    "ax[0,0].set_ylim(0,16)\n",
    "ax[0,0].set_title(\"Dummy image\")\n",
    "ax[0,1].set_xlim(964,981)\n",
    "ax[0,1].set_ylim(0,16)\n",
    "ax[0,1].set_title(\"Convolved image (i.e. blurred)\")\n",
    "ax[1,1].set_xlim(964,981)\n",
    "ax[1,1].set_ylim(0,16)\n",
    "ax[1,1].set_title(\"Retro-projected of the blurred\")\n",
    "ax[1,0].set_title(\"Corrected image\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterMLEM_scipy(F, M, R):\n",
    "    \"Implement one step of MLEM\"\n",
    "    #res = F * (R.T.dot(M))/R.dot(F)# / M.sum(axis=-1)\n",
    "    norm = 1/R.T.dot(numpy.ones_like(F)) \n",
    "    cor = R.T.dot(M/R.dot(F))\n",
    "    res = norm * F * cor\n",
    "    res[numpy.isnan(res)] = 1.0\n",
    "    return res\n",
    "\n",
    "def deconv_MLEM(csr, data, thres=0.2, maxiter=1000):\n",
    "    R = csr.T\n",
    "    msk = data<0\n",
    "    img = data.astype(\"float32\")\n",
    "    img[msk] = 0.0 # set masked values to 0, negative values could induce errors\n",
    "    M = img.ravel()\n",
    "    #F0 = numpy.random.random(data.size)#M#\n",
    "    F0 = R.T.dot(M)\n",
    "    F1 = iterMLEM_scipy(F0, M, R)\n",
    "    delta = abs(F1-F0).max()\n",
    "    for i in range(maxiter):\n",
    "        if delta<thres:\n",
    "            break\n",
    "        F2 = iterMLEM_scipy(F1, M, R)\n",
    "        delta = abs(F1-F2).max()\n",
    "        if i%100==0:\n",
    "            print(i, delta)\n",
    "        F1 = F2\n",
    "        i+=1\n",
    "    print(i, delta)\n",
    "    return F2.reshape(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time res = deconv_MLEM(csr, dummy_blurred, 1e-4)\n",
    "\n",
    "# ax[1,0].imshow(res)\n",
    "# ax[1,0].set_xlim(964,981)\n",
    "# ax[1,0].set_ylim(0,16)\n",
    "fig,ax = subplots()\n",
    "ax.imshow(res)\n",
    "ax.set_xlim(964,981)\n",
    "ax.set_ylim(0,16)\n",
    "ax.set_title(\"Corrected image\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion of the raytracing part:\n",
    "\n",
    "We are able to simulate the path and the absorption of the photon in the thickness of the detector. \n",
    "Numba helped substentially to make the raytracing calculation much faster. \n",
    "The signal of each pixel is indeed spread on the neighboors, depending on the position of the PONI and this effect can be inverted using sparse-matrix pseudo-inversion. \n",
    "The MLEM can garanteee that the total signal is conserved and that no pixel gets negative value.\n",
    "\n",
    "We will now save this sparse matrix to file in order to be able to re-use it in next notebook. But before saving it, it makes sense to spend some time in generating a high quality sparse matrix in throwing thousand rays per pixel in a grid of 64x64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pre_csr = thick.calc_csr(64)\n",
    "hq_csr = csr_matrix(pre_csr)\n",
    "from scipy.sparse import save_npz\n",
    "save_npz(\"csr.npz\",hq_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total execution time: {time.perf_counter()-start_time:.3f} s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
